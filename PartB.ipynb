{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from statistics import mode\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file to classify whether the student has a A score \n",
    "df_matA = pd.read_csv('mat_A.csv', sep=',')\n",
    "data = df_matA.to_numpy()[:, 1:]\n",
    "\n",
    "# standarize the data \n",
    "indices_to_standarize = []\n",
    "for i, feature in enumerate(data[0]):\n",
    "    if type(feature) != str and i != (data.shape[1]-1):\n",
    "        indices_to_standarize.append(i)\n",
    "\n",
    "for i in indices_to_standarize:\n",
    "    m = np.mean(data[:, i])\n",
    "    std = np.std(data[:, i])\n",
    "    data[:, i] = (data[:, i]-m)/std\n",
    "\n",
    "# split in to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:, :-1], data[:, -1], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(x1, x2):\n",
    "    total_dist = 0\n",
    "    \n",
    "    for i, feature in enumerate(x1):\n",
    "        # for numerical values, the distance is manhattan\n",
    "        if type(feature) != str:\n",
    "            total_dist += abs(x1[i] - x2[i])\n",
    "        # for categorical values, the distance is hamming\n",
    "        else:\n",
    "            if x1[i] != x2[i]:\n",
    "                total_dist += 1\n",
    "    return total_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(dists, k):\n",
    "    x_sorted = np.sort(dists)\n",
    "    min_values = x_sorted[:k]\n",
    "    indices = [dists.index(value) for value in min_values]\n",
    "    return indices\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "def knn(X_train, X_test, y_train, y_test, k):\n",
    "\n",
    "    y_pred = []\n",
    "\n",
    "    # for each test data\n",
    "    for x in X_test:\n",
    "        \n",
    "        # get an array represent the distance between x and each training data\n",
    "        distances = []\n",
    "        for x_train in X_train:\n",
    "            distances.append(dist(x, x_train))\n",
    "        \n",
    "        # find the k lowest distance\n",
    "        lowest_indices = find_min(distances, k)\n",
    "        \n",
    "        # majority vote from these k\n",
    "        pred = mode(y_train[lowest_indices])\n",
    "        \n",
    "        # append the predicted result to the prediction array\n",
    "        y_pred.append(pred)\n",
    "        \n",
    "    accuracy = sum(y_pred == y_test)/len(y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "def ann(data, unit_num1, act_func1, unit_num2, act_func2, unit_num3, act_func3):\n",
    "    random_seed = 0\n",
    "    os.environ['PYTHONHASHSEED']=str(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    tf.random.set_seed(random_seed)\n",
    "    \n",
    "    # process data by change yes/no to 0/1 and delete all categorical data:\n",
    "    new_data = data.copy()\n",
    "    columns_to_delete = []\n",
    "    for sample in new_data:\n",
    "        for i in range(len(sample)):\n",
    "            if sample[i] == 'yes':\n",
    "                sample[i] = 1\n",
    "            elif sample[i] == 'no':\n",
    "                sample[i] = 0\n",
    "    for i in range(len(new_data[0])):\n",
    "        if type(new_data[i][i]) == str:\n",
    "            columns_to_delete.append(i)\n",
    "\n",
    "    new_data = np.delete(new_data, columns_to_delete, axis = 1)\n",
    "    # split in to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_data[:, :-1], new_data[:, -1], test_size=0.1, random_state=0)\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "\n",
    "    # Initialize the ANN model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(units=unit_num1, activation=act_func1))\n",
    "    model.add(tf.keras.layers.Dense(units=unit_num2, activation=act_func2))\n",
    "    model.add(tf.keras.layers.Dense(units=unit_num3, activation=act_func3))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=100)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(data, crit, split, max_dep, min_samp_split):\n",
    "    # decision tree\n",
    "    # process data by change yes/no to 0/1 and delete all categorical data:\n",
    "    new_data = data.copy()\n",
    "    columns_to_delete = []\n",
    "    for sample in new_data:\n",
    "        for i in range(len(sample)):\n",
    "            if sample[i] == 'yes':\n",
    "                sample[i] = 1\n",
    "            elif sample[i] == 'no':\n",
    "                sample[i] = 0\n",
    "    for i in range(len(new_data[0])):\n",
    "        if type(new_data[i][i]) == str:\n",
    "            columns_to_delete.append(i)\n",
    "\n",
    "    new_data = np.delete(new_data, columns_to_delete, axis = 1)\n",
    "    # split in to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_data[:, :-1], new_data[:, -1], test_size=0.1, random_state=0)\n",
    "    y_train = y_train.tolist()\n",
    "    y_test = y_test.tolist()\n",
    "\n",
    "    # Creating a decision tree classifier\n",
    "    clf = DecisionTreeClassifier(criterion=crit, splitter=split, max_depth=max_dep, min_samples_split=min_samp_split, random_state=0)\n",
    "\n",
    "    # Fitting the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Making predictions on the test set\n",
    "    y_pred = clf.predict(X_test)  # clf is your trained decision tree classifier\n",
    "\n",
    "    # Evaluating the classifier\n",
    "    # Calculating accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n",
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.4867 - loss: 0.7149\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.8048 - loss: 0.5567\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.8348 - loss: 0.4719\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.8678 - loss: 0.3995\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 543us/step - accuracy: 0.9009 - loss: 0.3340\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594us/step - accuracy: 0.9181 - loss: 0.2813\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9180 - loss: 0.2410\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.9302 - loss: 0.2112\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - accuracy: 0.9324 - loss: 0.1875\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 565us/step - accuracy: 0.9377 - loss: 0.1690\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 535us/step - accuracy: 0.9427 - loss: 0.1537\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9487 - loss: 0.1408\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9622 - loss: 0.1298\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9629 - loss: 0.1200\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - accuracy: 0.9629 - loss: 0.1113\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9662 - loss: 0.1036\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.9684 - loss: 0.0965\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 0.9766 - loss: 0.0898\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557us/step - accuracy: 0.9748 - loss: 0.0837\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - accuracy: 0.9781 - loss: 0.0780\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - accuracy: 0.9810 - loss: 0.0728\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9810 - loss: 0.0679 \n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.9810 - loss: 0.0634\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.9852 - loss: 0.0591\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.9879 - loss: 0.0551\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 0.9879 - loss: 0.0513\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9911 - loss: 0.0477\n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9930 - loss: 0.0444\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.9970 - loss: 0.0415\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 536us/step - accuracy: 0.9982 - loss: 0.0386\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - accuracy: 1.0000 - loss: 0.0360\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 1.0000 - loss: 0.0336\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 1.0000 - loss: 0.0314\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 507us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 1.0000 - loss: 0.0254\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - accuracy: 1.0000 - loss: 0.0236\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 1.0000 - loss: 0.0220\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 1.0000 - loss: 0.0205\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 1.0000 - loss: 0.0157\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0138 \n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0129 \n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step - accuracy: 1.0000 - loss: 0.0084\n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574us/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 529us/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544us/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 1.0000 - loss: 0.0042\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0040 \n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589us/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 1.0000 - loss: 0.0026\n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 520us/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0016 \n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1089 \n",
      "0.949999988079071\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "print(knn(X_train, X_test, y_train, y_test, 5))\n",
    "print(ann(data, 64, 'relu', 32, 'relu', 1, 'sigmoid'))\n",
    "print(decision_tree(data, 'gini', 'best', 10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(data, n_estimators, criterion, max_depth, min_samples_split):\n",
    "    # decision tree\n",
    "    # process data by change yes/no to 0/1 and delete all categorical data:\n",
    "    new_data = data.copy()\n",
    "    columns_to_delete = []\n",
    "    for sample in new_data:\n",
    "        for i in range(len(sample)):\n",
    "            if sample[i] == 'yes':\n",
    "                sample[i] = 1\n",
    "            elif sample[i] == 'no':\n",
    "                sample[i] = 0\n",
    "    for i in range(len(new_data[0])):\n",
    "        if type(new_data[i][i]) == str:\n",
    "            columns_to_delete.append(i)\n",
    "    \n",
    "    new_data = np.delete(new_data, columns_to_delete, axis = 1)\n",
    "    # split in to training and testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_data[:, :-1], new_data[:, -1], test_size=0.1, random_state=0)\n",
    "    y_train = y_train.tolist()\n",
    "    y_test = y_test.tolist()\n",
    "    \n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split, random_state=42) \n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = rf_model.predict(X_test)\n",
    "    \n",
    "    return accuracy_score(y_test, predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n",
      "Epoch 1/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.4867 - loss: 0.7149\n",
      "Epoch 2/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - accuracy: 0.8048 - loss: 0.5567\n",
      "Epoch 3/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - accuracy: 0.8348 - loss: 0.4719\n",
      "Epoch 4/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 571us/step - accuracy: 0.8678 - loss: 0.3995\n",
      "Epoch 5/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.9009 - loss: 0.3340\n",
      "Epoch 6/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.9181 - loss: 0.2813\n",
      "Epoch 7/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - accuracy: 0.9180 - loss: 0.2410\n",
      "Epoch 8/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.9302 - loss: 0.2112\n",
      "Epoch 9/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545us/step - accuracy: 0.9324 - loss: 0.1875\n",
      "Epoch 10/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.9377 - loss: 0.1690\n",
      "Epoch 11/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 0.9427 - loss: 0.1537\n",
      "Epoch 12/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - accuracy: 0.9487 - loss: 0.1408\n",
      "Epoch 13/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - accuracy: 0.9622 - loss: 0.1298\n",
      "Epoch 14/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.9629 - loss: 0.1200\n",
      "Epoch 15/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561us/step - accuracy: 0.9629 - loss: 0.1113\n",
      "Epoch 16/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593us/step - accuracy: 0.9662 - loss: 0.1036\n",
      "Epoch 17/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step - accuracy: 0.9684 - loss: 0.0965\n",
      "Epoch 18/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 0.9766 - loss: 0.0898\n",
      "Epoch 19/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9748 - loss: 0.0837\n",
      "Epoch 20/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9781 - loss: 0.0780\n",
      "Epoch 21/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.9810 - loss: 0.0728\n",
      "Epoch 22/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - accuracy: 0.9810 - loss: 0.0679\n",
      "Epoch 23/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9810 - loss: 0.0634\n",
      "Epoch 24/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step - accuracy: 0.9852 - loss: 0.0591\n",
      "Epoch 25/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.9879 - loss: 0.0551\n",
      "Epoch 26/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 0.9879 - loss: 0.0513\n",
      "Epoch 27/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 0.0477 \n",
      "Epoch 28/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.9930 - loss: 0.0444\n",
      "Epoch 29/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9970 - loss: 0.0415\n",
      "Epoch 30/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 522us/step - accuracy: 0.9982 - loss: 0.0386\n",
      "Epoch 31/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 575us/step - accuracy: 1.0000 - loss: 0.0360\n",
      "Epoch 32/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583us/step - accuracy: 1.0000 - loss: 0.0336\n",
      "Epoch 33/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - accuracy: 1.0000 - loss: 0.0314\n",
      "Epoch 34/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 1.0000 - loss: 0.0292\n",
      "Epoch 35/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - accuracy: 1.0000 - loss: 0.0272\n",
      "Epoch 36/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 1.0000 - loss: 0.0254\n",
      "Epoch 37/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 1.0000 - loss: 0.0236\n",
      "Epoch 38/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - accuracy: 1.0000 - loss: 0.0220\n",
      "Epoch 39/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 1.0000 - loss: 0.0205\n",
      "Epoch 40/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - accuracy: 1.0000 - loss: 0.0192\n",
      "Epoch 41/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 1.0000 - loss: 0.0180\n",
      "Epoch 42/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - accuracy: 1.0000 - loss: 0.0168\n",
      "Epoch 43/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 506us/step - accuracy: 1.0000 - loss: 0.0157\n",
      "Epoch 44/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 1.0000 - loss: 0.0147\n",
      "Epoch 45/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 1.0000 - loss: 0.0138\n",
      "Epoch 46/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 1.0000 - loss: 0.0129\n",
      "Epoch 47/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 1.0000 - loss: 0.0121\n",
      "Epoch 48/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - accuracy: 1.0000 - loss: 0.0114\n",
      "Epoch 49/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 1.0000 - loss: 0.0107\n",
      "Epoch 50/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 1.0000 - loss: 0.0101\n",
      "Epoch 51/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 1.0000 - loss: 0.0095\n",
      "Epoch 52/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 1.0000 - loss: 0.0090\n",
      "Epoch 53/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0084 \n",
      "Epoch 54/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - accuracy: 1.0000 - loss: 0.0080\n",
      "Epoch 55/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 1.0000 - loss: 0.0075\n",
      "Epoch 56/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525us/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 57/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 1.0000 - loss: 0.0067\n",
      "Epoch 58/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 1.0000 - loss: 0.0064\n",
      "Epoch 59/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 1.0000 - loss: 0.0061\n",
      "Epoch 60/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 1.0000 - loss: 0.0057\n",
      "Epoch 61/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 1.0000 - loss: 0.0054\n",
      "Epoch 62/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - accuracy: 1.0000 - loss: 0.0052\n",
      "Epoch 63/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - accuracy: 1.0000 - loss: 0.0049\n",
      "Epoch 64/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 65/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 66/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - accuracy: 1.0000 - loss: 0.0042\n",
      "Epoch 67/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 68/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 69/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 567us/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 70/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 71/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 72/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 73/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 1.0000 - loss: 0.0031\n",
      "Epoch 74/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 75/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 76/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - accuracy: 1.0000 - loss: 0.0028\n",
      "Epoch 77/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 1.0000 - loss: 0.0026 \n",
      "Epoch 78/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 79/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 1.0000 - loss: 0.0025\n",
      "Epoch 80/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 81/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490us/step - accuracy: 1.0000 - loss: 0.0023\n",
      "Epoch 82/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - accuracy: 1.0000 - loss: 0.0022\n",
      "Epoch 83/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510us/step - accuracy: 1.0000 - loss: 0.0021\n",
      "Epoch 84/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 85/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - accuracy: 1.0000 - loss: 0.0020\n",
      "Epoch 86/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 87/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 1.0000 - loss: 0.0019\n",
      "Epoch 88/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 1.0000 - loss: 0.0018\n",
      "Epoch 89/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482us/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 90/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 1.0000 - loss: 0.0017\n",
      "Epoch 91/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 92/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 1.0000 - loss: 0.0016\n",
      "Epoch 93/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 94/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 1.0000 - loss: 0.0015\n",
      "Epoch 95/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 96/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 1.0000 - loss: 0.0014\n",
      "Epoch 97/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - accuracy: 1.0000 - loss: 0.0014   \n",
      "Epoch 98/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485us/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 99/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - accuracy: 1.0000 - loss: 0.0013   \n",
      "Epoch 100/100\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 1.0000 - loss: 0.0012   \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1089 \n",
      "0.949999988079071\n",
      "0.95\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(knn(X_train, X_test, y_train, y_test, 5))\n",
    "print(ann(data, 64, 'relu', 32, 'relu', 1, 'sigmoid'))\n",
    "print(decision_tree(data, 'gini', 'best', 10, 3))\n",
    "print(random_forest(data, 100, \"gini\", 10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9392405063291139\n",
      "Standard Deviation of Accuracy: 0.01679303691319191\n"
     ]
    }
   ],
   "source": [
    "# cross validation random forest\n",
    "\n",
    "def random_forest_cv(data, n_estimators, criterion, max_depth, min_samples_split):\n",
    "    # Process data\n",
    "    new_data = data.copy()\n",
    "    columns_to_delete = []\n",
    "    for sample in new_data:\n",
    "        for i in range(len(sample)):\n",
    "            if sample[i] == 'yes':\n",
    "                sample[i] = 1\n",
    "            elif sample[i] == 'no':\n",
    "                sample[i] = 0\n",
    "    for i in range(len(new_data[0])):\n",
    "        if type(new_data[i][i]) == str:\n",
    "            columns_to_delete.append(i)\n",
    "    new_data = np.delete(new_data, columns_to_delete, axis = 1)\n",
    "    data = new_data\n",
    "\n",
    "    # Define the model\n",
    "    rf_model = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion, \n",
    "                                      max_depth=max_depth, \n",
    "                                      min_samples_split=min_samples_split, \n",
    "                                      random_state=42)\n",
    "\n",
    "    # Split data into features and target\n",
    "    X = data[:, :-1]\n",
    "    y = data[:, -1]\n",
    "    y = y.tolist()\n",
    "\n",
    "    # Define K-Fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(rf_model, X, y, cv=kf, scoring='accuracy')\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    folds = range(1, 6)  # Folds: 1, 2, 3, 4, 5\n",
    "    plt.bar(folds, cv_scores, color='lightblue', edgecolor='black')\n",
    "    plt.axhline(y=mean_accuracy, color='r', linestyle='-', linewidth=2)\n",
    "    plt.text(5.5, mean_accuracy, f'Mean: {mean_accuracy:.2f}', color = 'red', va='center')\n",
    "\n",
    "    plt.title('Cross-Validation Accuracy Scores per Fold')\n",
    "    plt.xlabel('Fold')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(folds)\n",
    "    plt.ylim(0, 1)  # Assuming accuracy scores are between 0 and 1\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return np.mean(cv_scores), np.std(cv_scores)\n",
    "\n",
    "# Example usage with your data\n",
    "mean_accuracy, std_accuracy = random_forest_cv(data, n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
